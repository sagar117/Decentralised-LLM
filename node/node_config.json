{
  "model": "gpt2",
  "hardware": "A100",
  "max_tokens": 2048,
  "supports_streaming": true,
  "inference_server": false
}
